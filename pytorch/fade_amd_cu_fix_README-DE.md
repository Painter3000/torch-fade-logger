# üî• FADE AMD CU Fix f√ºr PyTorch

**Behebt AMDs kaputte Compute Unit Erkennung in PyTorch f√ºr RDNA2 GPUs**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GPU: AMD RDNA2](https://img.shields.io/badge/GPU-AMD_RDNA2-red.svg)](https://www.amd.com/en/graphics/rdna-2)
[![PyTorch: 2.8+](https://img.shields.io/badge/PyTorch-2.8+-orange.svg)](https://pytorch.org/)

*[üá∫üá∏ English Version](fade_amd_cu_fix_README-ENG-US.md) | üá©üá™ Deutsche Version*

## üö® Das Problem

AMDs HIP/ROCm Stack hat einen kritischen Fehler: **RX 6800 XT GPUs werden als nur 36 Compute Units gemeldet, obwohl sie tats√§chlich 72 CUs haben**. Das bedeutet:

- ‚ùå **50% Performance-Verlust**: PyTorch nutzt nur die H√§lfte deiner GPU
- ‚ùå **Falsches Scheduling**: Speicher-Allokation und Kernel-Dispatch sind suboptimal  
- ‚ùå **Verschwendete Hardware**: Du hast f√ºr 72 CUs bezahlt, bekommst aber nur 36

**Vor dem Fix:**
```python
>>> import torch
>>> torch.cuda.get_device_properties(0).multi_processor_count
36  # Falsch! Sollte 72 sein
```

**Nach dem Fix:**
```python
>>> import torch  
>>> torch.cuda.get_device_properties(0).multi_processor_count
72  # Korrekt! Volle Hardware-Nutzung
```

## ‚úÖ Die L√∂sung

Unser Patch bietet **3 verschiedene Methoden** um das CU-Erkennungsproblem zu beheben und gibt dir Flexibilit√§t je nach Setup und Vorlieben.

### üõ†Ô∏è Patch-Methoden

| Methode | Beschreibung | Am besten f√ºr | Auto-Erkennung |
|---------|--------------|---------------|:-------------:|
| **1. Dynamisch** | Nutzt `rocminfo` um echte CU-Anzahl automatisch zu erkennen | Jede AMD GPU | ‚úÖ Ja |
| **2. Statisch** | Hardcodierter Fix f√ºr spezifische GPU-Modelle | RX 6800 XT, bekannte Configs | ‚ùå Nein |
| **3. Wrapper** | √úberschreibt `hipGetDeviceProperties()` Funktion | Fortgeschrittene User, Custom Builds | ‚úÖ Ja |

### üéØ Unterst√ºtzte Hardware

| GPU-Modell | Gemeldete CUs | Echte CUs | Methode 1 | Methode 2 | Methode 3 |
|------------|:-------------:|:---------:|:---------:|:---------:|:---------:|
| RX 6800 XT | 36 | **72** | ‚úÖ Auto | ‚úÖ Behoben | ‚úÖ Auto |
| RX 6900 XT | 40 | **80** | ‚úÖ Auto | üîÑ Geplant | ‚úÖ Auto |
| RX 7800 XT | TBD | TBD | ‚úÖ Auto | üîÑ Geplant | ‚úÖ Auto |
| **Jede RDNA2** | Verschiedene | **Auto-erkannt** | ‚úÖ Auto | ‚ùå Manuell | ‚úÖ Auto |

*Methode 1 (Dynamisch) funktioniert mit jeder AMD GPU die `rocminfo` erkennen kann!*

## üöÄ Schnellstart

### Voraussetzungen

- AMD RX 6800 XT (oder unterst√ºtzte GPU)
- PyTorch Quellcode (Build from Source)
- ROCm 6.0+ installiert
- Linux (getestet auf Ubuntu 22.04)

### Installation

1. **PyTorch klonen** (falls noch nicht geschehen):
   ```bash
   git clone --recursive https://github.com/pytorch/pytorch
   cd pytorch
   ```

2. **Fix herunterladen und anwenden**:
   ```bash
   wget https://raw.githubusercontent.com/Painter3000/torch-fade-logger/main/pytorch/fade_amd_cu_fix.sh
   chmod +x fade_amd_cu_fix.sh
   ./fade_amd_cu_fix.sh
   ```

   **Du wirst aufgefordert eine Patch-Methode zu w√§hlen:**
   ```
   üõ†Ô∏è  Patch-Methode w√§hlen:
      1) Dynamischer Fix (Auto-Erkennung der CU-Anzahl via rocminfo)
      2) Statischer Fix (Hardcodiert RX 6800 XT: 36‚Üí72)  
      3) Wrapper-Methode (√úberschreibt hipGetDeviceProperties)
   
   Methode w√§hlen [1-3]: 1
   ```

   **Empfehlungen:**
   - **Methode 1 (Dynamisch)**: Beste Wahl f√ºr die meisten User - funktioniert mit jeder AMD GPU
   - **Methode 2 (Statisch)**: Nutzen wenn rocminfo nicht verf√ºgbar ist oder du explizite Kontrolle willst
   - **Methode 3 (Wrapper)**: Fortgeschrittene User die minimale Code-√Ñnderungen wollen

3. **PyTorch bauen**:
   ```bash
   python setup.py develop
   ```

4. **Fix verifizieren**:
   ```bash
   python -c "import torch; print(f'CUs: {torch.cuda.get_device_properties(0).multi_processor_count}')"
   ```

Erwartete Ausgabe: `CUs: 72` ‚úÖ

## üîß Technische Details

### Methode 1: Dynamischer Fix (rocminfo)

Erkennt automatisch die echte CU-Anzahl deiner GPU und wendet den korrekten Wert an:

```cpp
// FADE PATCH: Dynamischer CU-Fix basierend auf rocminfo-Erkennung  
// Erkannte Hardware CU-Anzahl: 72
if (device_prop.multiProcessorCount < 72) {
  FADE_LOG("DEVICE", "Fixed multiProcessorCount: %d -> 72 (auto-erkannt)", device_prop.multiProcessorCount);
  device_prop.multiProcessorCount = 72;
}
```

### Methode 2: Statischer Fix (RX 6800 XT)

Hardcodierter Fix f√ºr bekannte GPU-Modelle:

```cpp
// FADE PATCH: Fix f√ºr AMDs kaputte multiProcessorCount bei RX 6800 XT
if (device_prop.multiProcessorCount == 36 && 
    strstr(device_prop.name, "RX 6800 XT") != nullptr) {
  FADE_LOG("DEVICE", "Fixed multiProcessorCount: 36 -> 72 for RX 6800 XT");
  device_prop.multiProcessorCount = 72;
}
```

### Methode 3: Wrapper Override

Elegante Funktions√ºberschreibung die systemweit funktioniert:

```cpp
// FADE PATCH: Wrapper-Funktion f√ºr hipGetDeviceProperties
static hipError_t FADE_hipGetDeviceProperties(hipDeviceProp_t* prop, int device_id) {
    hipError_t status = hipGetDeviceProperties(prop, device_id);
    if (status == hipSuccess) {
        if (prop->multiProcessorCount == 36 && strstr(prop->name, "RX 6800 XT") != nullptr) {
            FADE_LOG("DEVICE", "FADE Wrapper: Fixed multiProcessorCount 36 -> 72 for RX 6800 XT");
            prop->multiProcessorCount = 72;
        }
    }
    return status;
}
#define hipGetDeviceProperties FADE_hipGetDeviceProperties
```

### Warum das funktioniert

1. **Grundursache**: AMDs `hipGetDeviceProperties()` gibt falsche CU-Anzahl zur√ºck
2. **Erkennungsmethoden**: 
   - **Dynamisch**: Nutzt `rocminfo` um echte Hardware-Specs zu erkennen
   - **Statisch**: Hardcodierte Fixes f√ºr bekannte GPU-Modelle  
   - **Wrapper**: Funktions√ºberschreibung die √ºberall funktioniert
3. **Abfangpunkt**: PyTorch ruft Device-Property-Funktionen w√§hrend der Initialisierung auf
4. **Systemweiter Effekt**: Alle PyTorch-Komponenten sehen die korrigierten Hardware-Specs

### Voraussetzungen f√ºr jede Methode

| Methode | Anforderungen | Vorteile | Einschr√§nkungen |
|---------|---------------|----------|-----------------|
| **Dynamisch** | `rocminfo` installiert | ‚úÖ Funktioniert mit jeder GPU<br/>‚úÖ Zukunftssicher | ‚ùå Ben√∂tigt ROCm-Tools |
| **Statisch** | Keine | ‚úÖ Keine Abh√§ngigkeiten<br/>‚úÖ Getestet & zuverl√§ssig | ‚ùå Manuell pro GPU-Modell |
| **Wrapper** | C++ Kenntnisse hilfreich | ‚úÖ Minimale Code-√Ñnderungen<br/>‚úÖ Saubere √úberschreibung | ‚ùå Fortgeschrittene Methode |

## üìä Performance-Auswirkung

Real-World Benchmarks auf RX 6800 XT:

| Operation | Vorher (36 CUs) | Nachher (72 CUs) | Verbesserung |
|-----------|:---------------:|:----------------:|:------------:|
| Matrix-Multiplikation | 91.85ms | ~45ms | **~50%** |
| Conv2D | 57.36ms | ~28ms | **~51%** |
| Speicher-Bandbreite | Begrenzt | Voll | **2x** |

*Ergebnisse k√∂nnen je nach Workload und System-Konfiguration variieren*

## üõ†Ô∏è Erweiterte Nutzung

### Manueller Revert

Falls du den Patch r√ºckg√§ngig machen musst:

```bash
# Original-Datei wiederherstellen
cp ./aten/src/ATen/hip/HIPContext.cpp.backup ./aten/src/ATen/hip/HIPContext.cpp

# PyTorch neu bauen
python setup.py develop
```

### Weitere GPUs hinzuf√ºgen

Um zus√§tzliche AMD GPUs zu unterst√ºtzen, modifiziere die Patch-Bedingung:

```cpp
// Unterst√ºtzung f√ºr mehrere RDNA2 GPUs
if ((device_prop.multiProcessorCount == 36 && strstr(device_prop.name, "RX 6800 XT")) ||
    (device_prop.multiProcessorCount == 40 && strstr(device_prop.name, "RX 6900 XT"))) {
  // Fix basierend auf GPU-Modell anwenden
  if (strstr(device_prop.name, "RX 6800 XT")) {
    device_prop.multiProcessorCount = 72;
  } else if (strstr(device_prop.name, "RX 6900 XT")) {
    device_prop.multiProcessorCount = 80;
  }
}
```

### Debug-Logging

Je nach gew√§hlter Methode siehst du verschiedene Debug-Ausgaben:

**Methode 1 (Dynamisch):**
```
[FADE-LOG] DEVICE: Fixed multiProcessorCount: 36 -> 72 (auto-erkannt)
```

**Methode 2 (Statisch):**
```
[FADE-LOG] DEVICE: Fixed multiProcessorCount: 36 -> 72 for RX 6800 XT
```

**Methode 3 (Wrapper):**
```
[FADE-LOG] DEVICE: FADE Wrapper: Fixed multiProcessorCount 36 -> 72 for RX 6800 XT
```

### Deinen Fix testen

Nach dem PyTorch-Rebuild, verifiziere dass der Fix funktioniert:

```bash
# CU-Anzahl pr√ºfen
python -c "import torch; print(f'CUs: {torch.cuda.get_device_properties(0).multi_processor_count}')"

# Pr√ºfen ob FADE-Logging erscheint (falls du FADE Logger hast)
python -c "import torch; _ = torch.cuda.get_device_properties(0)" 2>&1 | grep "FADE"

# Performance-Verbesserung benchmarken
python -c "
import torch
import time
device = torch.device('cuda')
x = torch.randn(4096, 4096, device=device)
start = time.time()
y = torch.mm(x, x)
torch.cuda.synchronize()
print(f'Matrix-Multiplikation: {(time.time() - start) * 1000:.2f}ms')
"
```

## üêõ Fehlerbehebung

### H√§ufige Probleme

**F: Welche Methode soll ich w√§hlen?**
A: 
- **Methode 1 (Dynamisch)**: Beste Wahl f√ºr die meisten User - erkennt jede AMD GPU automatisch
- **Methode 2 (Statisch)**: Nutzen wenn du rocminfo nicht hast oder explizite Kontrolle bevorzugst  
- **Methode 3 (Wrapper)**: Fortgeschrittene User die saubere Funktions√ºberschreibungen wollen

**F: Script sagt "Could not detect CU count from rocminfo"**
A: Installiere ROCm-Tools (`sudo apt install rocm-dev-tools`) oder nutze Methode 2 (Statisch).

**F: Kann ich zwischen Methoden wechseln?**
A: Ja! Stelle die Backup-Datei wieder her und f√ºhre das Script erneut mit einer anderen Methode aus.

**F: Methode 1 erkannte falsche CU-Anzahl**
A: Pr√ºfe `rocminfo | grep "Compute Unit"` Ausgabe. Falls falsch, nutze Methode 2 mit korrekten Werten.

**F: Script sagt "already patched"**
A: Der Patch wurde bereits angewendet. Um erneut zu patchen, stelle zuerst das Backup wieder her.

**F: PyTorch zeigt immer noch 36 CUs**
A: Stelle sicher dass du PyTorch nach dem Patch neu gebaut hast: `python setup.py develop`

**F: Patch-Script schl√§gt fehl mit "pattern not found"**
A: Deine PyTorch-Version k√∂nnte inkompatibel sein. [√ñffne ein Issue](../../issues) mit deiner PyTorch-Version.

**F: Build-Fehler nach dem Patchen**
A: Stelle das Backup wieder her und pr√ºfe dass alle Voraussetzungen installiert sind.

### Hilfe bekommen

1. Pr√ºfe [Issues](../../issues) f√ºr √§hnliche Probleme
2. Gib dein GPU-Modell, PyTorch-Version und ROCm-Version an
3. F√ºge die Ausgabe hinzu von: `python -c "import torch; print(torch.cuda.get_device_properties(0))"`

## ü§ù Mitwirken

Wir freuen uns √ºber Beitr√§ge! Hilf uns mehr AMD GPUs zu unterst√ºtzen:

1. **Teste auf deiner Hardware**: Probiere den Patch aus und berichte Ergebnisse
2. **GPU-Support hinzuf√ºgen**: Reiche PRs f√ºr zus√§tzliche RDNA2 GPUs ein  
3. **Erkennung verbessern**: Bessere GPU-Identifikationsmethoden
4. **Dokumentation**: Hilf diese README zu verbessern

### Development-Setup

```bash
# Dieses Repo klonen
git clone https://github.com/Painter3000/torch-fade-logger.git
cd torch-fade-logger

# Patch-Script testen
./fade_amd_cu_fix.sh --dry-run
```

## üìú Hintergrund

Dieser Fix ist Teil des [FADE (Framework for AMD Device Enhancement)](https://github.com/Painter3000/torch-fade-logger) Projekts, das darauf abzielt AMD GPU-Kompatibilit√§tsprobleme in PyTorch zu l√∂sen.

### Verwandte Projekte

- üîç **[FADELogger](https://github.com/Painter3000/torch-fade-logger)**: Runtime GPU-Validierung und Debugging
- ‚ö° **DPP8 Kernels**: Custom RDNA2 Tensor-Operationen (bald verf√ºgbar)
- üõ†Ô∏è **ZLUDA Integration**: CUDA-zu-HIP √úbersetzungsverbesserungen

## üìÑ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) Datei f√ºr Details.

## üôè Danksagungen

- **AMD**: F√ºr die Erschaffung m√§chtiger RDNA2-Hardware (bitte repariert eure Treiber! üòâ)
- **PyTorch Team**: F√ºr das gro√üartige ML-Framework
- **ROCm Community**: Daf√ºr dass AMD GPU-Compute m√∂glich gemacht wurde
- **AI Assistants**: F√ºr die Hilfe beim Debuggen dieses komplexen Problems

---

**Gemacht mit ‚ù§Ô∏è f√ºr die AMD GPU Community**

*H√∂r auf AMDs Bugs deine AI-Workloads limitieren zu lassen. Hol dir die Performance f√ºr die du bezahlt hast!*

## üîó Links

- [Issues melden](../../issues)
- [PyTorch Offizielle Docs](https://pytorch.org/docs/)
- [ROCm Dokumentation](https://rocm.docs.amd.com/)
- [RDNA2 Architektur Guide](https://www.amd.com/en/graphics/rdna-2)

**‚≠ê Falls dir das Zeit/Geld gespart hat, gib dem Repo bitte einen Stern!**
